{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFNkvjgn1lPI"
      },
      "source": [
        "## Fine-tuning Stable Diffusion XL with DreamBooth and LoRA\n",
        "\n",
        "In this notebook, we fine-tune [Stable Diffusion XL (SDXL)](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/stable_diffusion_xl) with [DreamBooth](https://huggingface.co/docs/diffusers/main/en/training/dreambooth) and [LoRA](https://huggingface.co/docs/diffusers/main/en/training/lora).\n",
        "\n",
        "We prepared our own dataset. The details are mentioned in the documentation.\n",
        "We picked to fine tune it on images of Micheal Scott from The Office.\n",
        "You can use this code to fine-tune your model on something else.\n",
        "Make sure to **connect to a T4 GPU** before running this notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "pdM59WIoS01O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUxRrLfLMnBb"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installing dependencies**"
      ],
      "metadata": {
        "id": "PaU712uYv-cS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55U57alsRIek"
      },
      "outputs": [],
      "source": [
        "!pip install bitsandbytes transformers accelerate peft -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9atNWUXFZlVe"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/huggingface/diffusers.git -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2TRPaxGx3mE"
      },
      "source": [
        "now we download diffusers SDXL DreamBooth training script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQpqmq7rx3mE"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/huggingface/diffusers/main/examples/dreambooth/train_dreambooth_lora_sdxl.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRBcvYAyS8bU"
      },
      "source": [
        "## **Dataset (training data)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvTS06eEx3mF"
      },
      "source": [
        "upload example images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqqhZ9R9x3mG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "local_dir = \"./micheal_scott/\"\n",
        "os.makedirs(local_dir)\n",
        "os.chdir(local_dir)\n",
        "\n",
        "uploaded_images = files.upload()\n",
        "os.chdir(\"/content\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piJkbOe9OZbX"
      },
      "source": [
        "Preview the images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0R-hByAPkIg"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def image_grid(imgs, rows, cols, resize=256):\n",
        "\n",
        "    if resize is not None:\n",
        "        imgs = [img.resize((resize, resize)) for img in imgs]\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
        "    grid_w, grid_h = grid.size\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
        "    return grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwhwepFrPwqo"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "# change path to display images from your local dir\n",
        "img_paths = \"./micheal_scott/*.jpg\"\n",
        "imgs = [Image.open(path) for path in glob.glob(img_paths)]\n",
        "\n",
        "num_imgs_to_preview = 5\n",
        "image_grid(imgs[:num_imgs_to_preview], 1, num_imgs_to_preview)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_5Skm_cx3mI"
      },
      "source": [
        "Free some memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4wfEW_cx3mI"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLptJV1vx3mI"
      },
      "source": [
        "## Training setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WW7eFPl4eYXy"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!accelerate config default"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc0bxTr918es"
      },
      "source": [
        "We passed the access token so that we can push the trained checkpoints to the Hugging Face Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Hf07sapecFY"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login('***********')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2-p7R70THc5"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZbz4IXe0bAn"
      },
      "source": [
        "### Launch training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTZuM7yNNZsT"
      },
      "outputs": [],
      "source": [
        "!pip install datasets -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " - Use `--output_dir` to specify your LoRA model repository name!\n",
        " - Use `--caption_column` to specify name of the cpation column in your dataset. In this example we used \"prompt\" to\n",
        " save our captions in the\n",
        " metadata file, change this according to your needs."
      ],
      "metadata": {
        "collapsed": false,
        "id": "fbri7qQ0mdyg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** here we are reszing the images to make them the same dimension by adding padding (This can be skipped). Our target is 1024 pixels. You can change it accordingly **"
      ],
      "metadata": {
        "id": "DmqEtUPz08Ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageOps\n",
        "import os\n",
        "\n",
        "input_folder = '/content/micheal_scott'\n",
        "output_folder = '/content/micheal_scott_new'\n",
        "target_size = 1024\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for filename in os.listdir(input_folder):\n",
        "    if not filename.lower().endswith(('.png', '.jpg', '.jpeg', '.webp')):\n",
        "        continue\n",
        "\n",
        "    img = Image.open(os.path.join(input_folder, filename)).convert(\"RGB\")\n",
        "    img.thumbnail((target_size, target_size), Image.LANCZOS)\n",
        "\n",
        "    delta_w = target_size - img.width\n",
        "    delta_h = target_size - img.height\n",
        "    padding = (delta_w // 2, delta_h // 2, delta_w - (delta_w // 2), delta_h - (delta_h // 2))\n",
        "    img = ImageOps.expand(img, padding, fill=(0, 0, 0))\n",
        "\n",
        "    img.save(os.path.join(output_folder, filename), quality=95)\n"
      ],
      "metadata": {
        "id": "PusGDB9EK5u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "id": "avbGb2z7BqtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOiZSXHfx3mJ"
      },
      "outputs": [],
      "source": [
        "!accelerate launch train_dreambooth_lora_sdxl.py \\\n",
        "  --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\" \\\n",
        "  --pretrained_vae_model_name_or_path=\"madebyollin/sdxl-vae-fp16-fix\" \\\n",
        "  --dataset_name=\"micheal_scott_new\" \\\n",
        "  --output_dir=\"micheal_scott_LoRA_29_1024\" \\\n",
        "  --caption_column=\"prompt\"\\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --instance_prompt=\"a portrait photo of Micheal Scott, office setting, realistic lighting\" \\\n",
        "  --resolution=1024 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=2 \\\n",
        "  --gradient_checkpointing \\\n",
        "  --learning_rate=1e-4 \\\n",
        "  --snr_gamma=5.0 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --use_8bit_adam \\\n",
        "  --max_train_steps=2000 \\\n",
        "  --checkpointing_steps=500 \\\n",
        "  --seed=\"0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i11tgWz5x3mK"
      },
      "source": [
        "### Save your model to the hub and check it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uyy9n54EtBY"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import whoami\n",
        "from pathlib import Path\n",
        "\n",
        "output_dir = \"micheal_scott_LoRA_29_1024\"\n",
        "username = whoami(token=Path(\"/root/.cache/huggingface/\"))[\"name\"]\n",
        "repo_id = f\"{username}/{output_dir}_29i_1024\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smLheRkvEQ9H"
      },
      "outputs": [],
      "source": [
        "# @markdown\n",
        "\n",
        "from train_dreambooth_lora_sdxl import save_model_card\n",
        "from huggingface_hub import upload_folder, create_repo\n",
        "\n",
        "repo_id = create_repo(repo_id, exist_ok=True).repo_id\n",
        "\n",
        "save_model_card(\n",
        "    repo_id = repo_id,\n",
        "    images=[],\n",
        "    base_model=\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    train_text_encoder=False,\n",
        "    instance_prompt=\"a photo of Micheal Scott from the office\",\n",
        "    validation_prompt=None,\n",
        "    repo_folder=output_dir,\n",
        "    vae_path=\"madebyollin/sdxl-vae-fp16-fix\",\n",
        "    use_dora=False\n",
        ")\n",
        "\n",
        "upload_folder(\n",
        "    repo_id=repo_id,\n",
        "    folder_path=output_dir,\n",
        "    commit_message=\"End of training\",\n",
        "    ignore_patterns=[\"step_*\", \"epoch_*\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLoRqZGux3mK"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "link_to_model = f\"https://huggingface.co/{repo_id}\"\n",
        "display(Markdown(\"### Your model has finished training.\\nAccess it here: {}\".format(link_to_model)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH7-YJwMcyra"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTz6Zmfc0i-0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import DiffusionPipeline, AutoencoderKL\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16)\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    vae=vae,\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\",\n",
        "    use_safetensors=True\n",
        ")\n",
        "pipe.load_lora_weights(repo_id)\n",
        "_ = pipe.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5J1NsUP51E2w"
      },
      "outputs": [],
      "source": [
        "prompt = \"A side profile shot of Michael Scott from The Office, wearing a dark suit, a striped dress shirt, and a dark patterned tie. He is standing in the office with his hands resting on a counter, looking intently to his right. An EXIT sign is visible in the background.\" # @param\n",
        "\n",
        "image = pipe(prompt=prompt, num_inference_steps=25).images[0]\n",
        "image"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
